# ğŸ›¡ï¸ Red Teaming the Prompt: A Complete Hackerâ€™s Guide to LLM Exploits

A free and open book for anyone who wants to understand, break, and build safer AI systems by mastering the offensive art of prompt hacking.

> âš ï¸ **Ethical Use Only**  
> This content is for educational red teaming and research. Misuse may violate laws or terms. See [DISCLAIMER.md](DISCLAIMER.md) for full legal and ethical guidance.

---

## ğŸ”¥ What This Is

**Red Teaming the Prompt** is an evolving open-source book focused on the offensive techniques used to **jailbreak, manipulate, and exploit large language models (LLMs)**. Inspired by the incredible work at [LearnPrompting.org](https://learnprompting.org/docs/prompt_hacking/offensive_measures/introduction), this project expands on those strategies â€” with deeper analogies, real-world social engineering parallels, reusable attack templates, and red team labs you can run yourself.

Whether youâ€™re an **AI red teamer, prompt engineer, cybersecurity pro, or curious builder**, this book aims to make the dark arts of adversarial prompting not only understandable, but _masterable_.

---

## ğŸ“š What's Inside

Each chapter focuses on **one offensive tactic**, such as:

- ğŸ§  Simple Instruction Override
- ğŸ”€ Context Switching
- ğŸ’£ Obfuscation & Token Smuggling
- ğŸ§© Recursive Prompt Injection
- ğŸ§™ Pretending & Role Hijacking
- ğŸ› ï¸ Alignment Hacking
- ğŸ§¬ Bad Chain-of-Thought Exploits  
  ...and many more.

Each chapter includes:

- ğŸ•µï¸ A **real-world social engineering analogy** to build intuition
- ğŸ’» LLM examples of the attack in action
- ğŸ§° Prompt templates and reusable tactics
- ğŸ§ª Mini red team lab to try the attack yourself
- ğŸ“‰ Why defenses fail â€” and how they might improve

---

## ğŸ“š Table of Contents

### ğŸ§­ Part I â€“ Foundations
- [Chapter 1 â€“ Introduction](./chapters/01-intro.md)
- [Chapter 2 â€“ Understanding the LLM Attack Surface](./chapters/02-llm-attack-surface.md)

---

### âš”ï¸ Part II â€“ Offensive Techniques
- [Chapter 3 â€“ Simple Instruction Attacks](./chapters/03-simple-instruction.md)
- [Chapter 4 â€“ Context Ignoring Attacks](./chapters/04-context-ignoring.md)
- [Chapter 5 â€“ Compound Instruction Attacks](./chapters/05-compound-instruction.md)
- [Chapter 6 â€“ Special Case Attacks](./chapters/06-special-case.md)
- [Chapter 7 â€“ Few-Shot Attacks](./chapters/07-few-shot.md)
- [Chapter 8 â€“ Refusal Suppression](./chapters/08-refusal-suppression.md)
- [Chapter 9 â€“ Context Switching Attacks](./chapters/09-context-switching.md)
- [Chapter 10 â€“ Obfuscation and Token Smuggling](./chapters/10-obfuscation.md)
- [Chapter 11 â€“ Task Deflection Attacks](./chapters/11-task-deflection.md)  
- [Chapter 12 â€“ Payload Splitting](./chapters/12-payload-splitting.md)  
- [Chapter 13 â€“ Defined Dictionary Attacks](./chapters/13-defined-dictionary.md)  
- [Chapter 14 â€“ Indirect Injection](./chapters/14-indirect-injection.md)  
- [Chapter 15 â€“ Recursive Injection](./chapters/15-recursive-injection.md)  
- [Chapter 16 â€“ Code Injection](./chapters/16-code-injection.md)  
- [Chapter 17 â€“ Virtualization Attacks](./chapters/17-virtualization.md)  
- [Chapter 18 â€“ Pretending & Role Prompting](./chapters/18-pretending.md)  
- [Chapter 19 â€“ Alignment Hacking](./chapters/19-alignment-hacking.md)  
- [Chapter 20 â€“ Authorized User Attacks](./chapters/20-authorized-user.md)  
- [Chapter 21 â€“ DAN and Persona-Based Jailbreaks](./chapters/21-dan.md)  
- [Chapter 22 â€“ Bad Chain-of-Thought Reasoning](./chapters/22-bad-chain.md)

---

### ğŸ” Part III â€“ Red Team Ops & Defense
- [Chapter 23 â€“ Building a Red Team Lab](./chapters/23-red-team-lab.md)
- [Chapter 24 â€“ Mapping to OWASP LLM Top 10](./chapters/24-owasp-mapping.md)
- [Chapter 25 â€“ Ethics, Disclosure, and Responsible Use](./chapters/25-ethics-disclosure.md)
- [Chapter 26 â€“ Going Further: Labs, Challenges & Real-World Practice](./chapters/26-going-further.md)

ğŸ“„ Full [SUMMARY.md](./SUMMARY.md)

---

## ğŸ§± Inspired By

This book builds on excellent open research from:

- [LearnPrompting.org](https://learnprompting.org/docs/prompt_hacking/offensive_measures/introduction) â€“ foundational prompt hacking concepts
- [HackAPrompt](https://huggingface.co/datasets/hackaprompt/hackaprompt-dataset) â€“ adversarial prompt dataset
- [WithSecure Labs](https://github.com/WithSecureLabs) â€“ vulnerable LLM apps for practice
- [OWASP Top 10 for LLMs](https://owasp.org/www-project-top-10-for-large-language-model-applications/) â€“ risk modeling and mitigation

We aim to make these concepts even more **practical, hands-on, and accessible** to anyone learning how language models can be tricked â€” and how to defend against it.

---

## ğŸ§  Who This Is For

- Red teamers working with LLMs
- Prompt engineers and jailbreakers
- Security researchers exploring AI threats
- Builders integrating LLMs into apps and agents
- Learners who want to â€œsee behind the curtainâ€ of language model safety

---

## âœï¸ Contributing

Want to help? Found a new jailbreak? Have a prompt that bypasses GPT-4â€™s defenses?

> ğŸ“¬ [Open an issue](https://github.com/randalltr/red-teaming-the-prompt/issues) or send a pull request â€” we welcome real-world attack examples, new chapters, and research references.

---

## âš–ï¸ License

All content is published under the **Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0))** license â€” inspired by [Learn Promptingâ€™s open license](https://learnprompting.org/docs/introduction). Feel free to share, remix, or adapt the content â€” just give proper attribution, donâ€™t use it commercially, and keep it under the same open license. [View full license](LICENSE)

---

## ğŸ§­ Start Reading

ğŸ‘‰ Head to [`SUMMARY.md`](SUMMARY.md) to dive into the book  
ğŸ‘‰ Or begin with [`01-intro.md`](./chapters/01-intro.md) â€“ _What is prompt hacking, and why should we care?_

---

> ğŸ§¨ Language is a weapon. Learn how to wield it.
